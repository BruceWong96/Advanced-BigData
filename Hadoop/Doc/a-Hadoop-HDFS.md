# Hadoop-HDFS

## 简介

HDFS = Hadoop Distributed File System，分布式文件系统，简而言之，就是文件太多，不能放在一台机器上，所以分到很多机器上进行存储。其实还有很关键的一点——高可用，存放在多台机器上可以设置副本，这样，当一台机器宕机后，数据不会丢失，因为其他机器上还存在副本。

## 架构

![HDFS 架构](../Picture/HDFS-Architecture.png)

- Block 数据块

    1. 基本存储单位，一般大小为 64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在 NameNode 上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本）
    2. 一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于 Block 大小，那么实际占用的空间为其文件的大小
    3. 基本的读写单位，类似于磁盘的页，每次都是读写一个块
    4. 每个块都会被复制到多台机器，默认复制 3 份

- NameNode

    1. 存储文件的 metadata，运行时所有数据都保存到内存，整个 HDFS 可存储的文件数受限于 NameNode 的内存大小
    2. 一个 Block 在 NameNode 中对应一条记录（一般一个 block 占用 150 字节），如果是大量的小文件，会消耗大量内存。同时 map task 的数量是由 splits 来决定的，所以用 MapReduce 处理大量的小文件时，就会产生过多的 map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此 Hadoop 建议存储大文件
    3. 数据会定时保存到本地磁盘，但不保存 block 的位置信息，而是由 DataNode 注册时上报和运行时维护（ NameNode 中与 DataNode 相关的信息并不保存到 NameNode 的文件系统中，而是 NameNode 每次重启后，动态重建）
    4. NameNode 失效则整个 HDFS 都失效了，所以要保证 NameNode 的可用性

- Secondary NameNode

    1. 定时与 NameNode 进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给 NameNode，替换其镜像，并清空编辑日志，类似于 CheckPoint 机制），但 NameNode 失效后仍需要手工将其设置成主机

- DataNode

    1. 保存具体的 block 数据
    2. 负责数据的读写操作和复制操作
    3. DataNode 启动时会向 NameNode 报告当前存储的数据块信息，后续也会定时报告修改信息
    4. DataNode 之间会进行通信，复制数据块，保证数据的冗余性